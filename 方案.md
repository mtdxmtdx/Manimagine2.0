先给个总体思路：你要做的是一个“小型 Manim 生成器代理系统”，前端只收自然语言描述，后端用 \*\*kimi-k2-thinking\*\* 按你在 \*提示词.md\* 里写好的规则产出 Manim CE 代码，然后本地调用 `manim` 渲染成视频即可。下面我按“架构 → 关键细节 → 示例代码”的方式给一个完整可落地的方案。



（我会直接把 `提示词.md` 里的内容作为系统提示词使用，并在此基础上稍微加几条“给机器看的约束”，方便自动解析代码。）



---



\## 一、整体架构设计



\### 1.1 模块划分



可以按下面 4 个模块实现：



1\. \*\*前端（可选简化）\*\*



&nbsp;  \* 一个简单网页 / CLI：



&nbsp;    \* 输入：自然语言描述（中文即可，例如“可视化傅里叶级数收敛过程”）

&nbsp;    \* 可选参数：分辨率、质量、输出文件名等

&nbsp;  \* 把用户输入发给后端 REST 接口：`POST /generate-manim-video`



2\. \*\*后端服务（Python）\*\*



&nbsp;  \* 核心逻辑：



&nbsp;    1. 读取并拼接 `提示词.md` 作为系统提示词

&nbsp;    2. 使用 Moonshot 的 \*\*chat completions\*\* 接口，模型为 `kimi-k2-thinking`

&nbsp;    3. 解析返回内容，提取 Manim CE 代码块

&nbsp;    4. 落盘为 `generated\_scene.py`

&nbsp;    5. 调用 `manim` 命令渲染视频

&nbsp;  \* 技术栈：`FastAPI` / `Flask` + `openai` 官方 SDK（兼容 Moonshot）(\[Moonshot AI]\[1])



3\. \*\*LLM 调用层（Kimi k2 thinking）\*\*



&nbsp;  \* 使用 `https://api.moonshot.cn/v1/chat/completions`，model 设为 `kimi-k2-thinking`(\[Moonshot AI]\[2])

&nbsp;  \* 请求参数要点：



&nbsp;    \* `max\_tokens` 尽量设大一些（例如 4096–8000；官方建议 reasoning 任务 ≥16000，根据你场景适当权衡）(\[Moonshot AI]\[2])

&nbsp;    \* `temperature` 推荐 0.6–1.0（Moonshot 对 thinking 系列建议 1.0，不过代码生成可以视稳定性往下调一点）(\[Moonshot AI]\[1])

&nbsp;    \* 按文档保留并传递 `reasoning\_content`（用于 debug 或展示“思考过程”）(\[Moonshot AI]\[2])



4\. \*\*渲染执行层（Manim Community Edition）\*\*



&nbsp;  \* 本地安装 \*\*Manim CE v0.19.0\*\*（当前稳定版），`pip install manim` 即可(\[Manim Community | Documentation]\[3])

&nbsp;  \* 后端通过 `subprocess` 调用：



&nbsp;    ```bash

&nbsp;    manim -qk generated\_scene.py GeneratedScene

&nbsp;    ```

&nbsp;  \* 输出 mp4 文件路径返回给前端。



---



\## 二、提示词（Prompt）设计与调用方式



\### 2.1 使用 `提示词.md` 作为 system prompt



你在 `提示词.md` 中已经写好了一个\*\*多步骤角色设定\*\*，包括：



\* 第一步：把用户的简单描述扩展成详细、带 LaTeX 的“视觉脚本”

\* 第二步：根据脚本生成 Manim CE 代码

\* 第三步：检查代码的 LaTeX / 变量 / 语法问题

\* 以及对：



&nbsp; \* 颜色、位置、大小、相机运动、时间信息

&nbsp; \* `Text` / `MathTex` / `VGroup` 的使用规范

&nbsp;   都有明确要求。



这是非常适合作为 \*\*system message\*\* 的内容。建议：



1\. \*\*原样放入 system role\*\*

2\. 额外在 system prompt 末尾加几条“机器可读约束”，方便后端解析代码，例如：



&nbsp;  ````text

&nbsp;  在给出最终 Manim 社区版代码时，请务必遵守以下额外规则：

&nbsp;  1. 所有可运行的 Python 代码必须放在一个 ```python 代码块中。

&nbsp;  2. 场景类统一命名为 GeneratedScene，且继承自 MovingCameraScene。

&nbsp;  3. 不要在代码块外再重复粘贴一遍代码。

&nbsp;  4. 在给出代码之前，可以先给出“第 1 步详细提示词”“第 2 步代码”“第 3 步自查结果”的自然语言说明。

&nbsp;  ````



\### 2.2 消息结构（传给 Kimi）



调用 `kimi-k2-thinking` 时，消息大致结构如下：(\[Moonshot AI]\[1])



````python

from openai import OpenAI



client = OpenAI(

&nbsp;   api\_key=os.environ\["MOONSHOT\_API\_KEY"],

&nbsp;   base\_url="https://api.moonshot.cn/v1",

)



SYSTEM\_PROMPT = open("提示词.md", encoding="utf-8").read() + """

在给出最终 Manim 社区版代码时，请务必遵守以下额外规则：

1\. 所有可运行的 Python 代码必须放在一个 ```python 代码块中。

2\. 场景类统一命名为 GeneratedScene，且继承自 MovingCameraScene。

3\. 不要在代码块外再重复粘贴一遍代码。

4\. 在给出代码之前，可以先给出“第 1 步详细提示词”“第 2 步代码”“第 3 步自查结果”的自然语言说明。

"""



def call\_kimi\_for\_manim(user\_description: str):

&nbsp;   messages = \[

&nbsp;       {"role": "system", "content": SYSTEM\_PROMPT},

&nbsp;       {

&nbsp;           "role": "user",

&nbsp;           "content": (

&nbsp;               "下面是用户的 Manim 动画需求，请按你任务说明的三步来完成：\\n"

&nbsp;               f"{user\_description}\\n\\n"

&nbsp;               "请记得：最终的可运行 Manim 代码必须只出现在一个 ```python 代码块中。"

&nbsp;           ),

&nbsp;       },

&nbsp;   ]

&nbsp;   completion = client.chat.completions.create(

&nbsp;       model="kimi-k2-thinking",

&nbsp;       messages=messages,

&nbsp;       max\_tokens=4096,

&nbsp;       temperature=0.8,  # 或 1.0，视稳定性调整

&nbsp;   )

&nbsp;   return completion.choices\[0].message

````



> 如果你想利用 `reasoning\_content` 看模型“思考过程”，可以用 `hasattr(message, "reasoning\_content")` / `getattr` 取出来。(\[Moonshot AI]\[2])



---



\## 三、服务端渲染流程设计



\### 3.1 核心流程（后端逻辑）



伪代码步骤：



1\. 接收前端请求（描述文本 + 可选参数）

2\. 调用 `call\_kimi\_for\_manim(user\_description)`

3\. 从返回的 `message.content` 中用正则 / Markdown 解析库提取 ```python 代码块

4\. 写入 `generated\_scene.py`

5\. 可选：先用 `python -m py\_compile` 做语法检查

6\. 调用 `manim` 命令渲染视频

7\. 把视频路径 / 下载 URL 返回给前端



\### 3.2 代码块提取示例



````python

import re

from pathlib import Path

import subprocess

import tempfile



CODE\_BLOCK\_RE = re.compile(

&nbsp;   r"```python\\s\*(?P<code>.\*?)```",

&nbsp;   re.DOTALL | re.IGNORECASE,

)



def extract\_python\_code(text: str) -> str:

&nbsp;   m = CODE\_BLOCK\_RE.search(text)

&nbsp;   if not m:

&nbsp;       raise ValueError("未找到 ```python 代码块，请检查提示词或模型输出。")

&nbsp;   return m.group("code").strip()



def save\_and\_render\_manim(code: str, work\_dir: Path) -> Path:

&nbsp;   work\_dir.mkdir(parents=True, exist\_ok=True)

&nbsp;   script\_path = work\_dir / "generated\_scene.py"

&nbsp;   script\_path.write\_text(code, encoding="utf-8")



&nbsp;   # 可选：先做语法检查

&nbsp;   subprocess.run(

&nbsp;       \["python", "-m", "py\_compile", str(script\_path)],

&nbsp;       check=True,

&nbsp;   )



&nbsp;   # 调用 manim 渲染，-qk：中等质量 + 保留文件

&nbsp;   # 场景名统一是 GeneratedScene（在 prompt 中已经约定）

&nbsp;   subprocess.run(

&nbsp;       \["manim", "-qk", str(script\_path), "GeneratedScene"],

&nbsp;       check=True,

&nbsp;       cwd=work\_dir,

&nbsp;   )



&nbsp;   # Manim 的默认输出路径类似：media/videos/generated\_scene/1080p60/GeneratedScene.mp4

&nbsp;   # 这里简单假设路径结构固定，可以根据 manim 输出再做精细处理

&nbsp;   video\_dir = work\_dir / "media" / "videos"

&nbsp;   video\_path = next(video\_dir.rglob("GeneratedScene.mp4"))

&nbsp;   return video\_path



def generate\_manim\_video(user\_description: str) -> Path:

&nbsp;   message = call\_kimi\_for\_manim(user\_description)

&nbsp;   code = extract\_python\_code(message.content)



&nbsp;   with tempfile.TemporaryDirectory() as tmpdir:

&nbsp;       work\_dir = Path(tmpdir)

&nbsp;       video\_path = save\_and\_render\_manim(code, work\_dir)

&nbsp;       # 你可以把视频复制到正式存储位置，再返回路径

&nbsp;       final\_path = Path("outputs") / video\_path.name

&nbsp;       final\_path.parent.mkdir(parents=True, exist\_ok=True)

&nbsp;       final\_path.write\_bytes(video\_path.read\_bytes())

&nbsp;   return final\_path

````



\### 3.3 暴露 REST 接口（FastAPI 示例）



```python

from fastapi import FastAPI

from pydantic import BaseModel



app = FastAPI()



class GenRequest(BaseModel):

&nbsp;   description: str



class GenResponse(BaseModel):

&nbsp;   video\_path: str



@app.post("/generate-manim-video", response\_model=GenResponse)

def generate\_manim(req: GenRequest):

&nbsp;   video\_path = generate\_manim\_video(req.description)

&nbsp;   return GenResponse(video\_path=str(video\_path))

```



---



\## 四、Kimi k2 thinking 的使用细节与优化



官方对 `kimi-k2-thinking` 的建议（你方案里可以按需采纳）：(\[Moonshot AI]\[2])



1\. \*\*保留 reasoning\_content 到上下文\*\*：

&nbsp;  如果你要做“多轮修复”（比如第一次代码报错，再把报错信息连同原输出继续喂回模型），建议把上一轮的 `message`（包含 `reasoning\_content`）也放入 `messages` 中，这有助于模型保持推理连贯。



2\. \*\*max\_tokens 适当放大\*\*：

&nbsp;  `kimi-k2-thinking` 的输出会包含 reasoning + 最终 content，token 消耗更高，官方建议 `max\_tokens >= 16000` 避免截断。你这里 Manim 代码不是特别长，可以稍微保守，但不要太小（比如 2048 以下）以免中途被截断。



3\. \*\*temperature\*\*：



&nbsp;  \* 官方建议：thinking 系列 `temperature=1.0`(\[Moonshot AI]\[1])

&nbsp;  \* 代码生成希望更稳定可重复，可以折中设置在 `0.6–0.8` 之间，并通过 prompt 强调“避免随机风格”。



4\. \*\*流式输出（可选）\*\*：



&nbsp;  \* 若你想在前端实时展示“思考过程”（类似 Terminal 中逐字输出），可以开启 `stream=True`，在服务端处理 SSE/流式响应。

&nbsp;  \* 对渲染流程本身没硬性要求，不开流也完全可行。



---



\## 五、Manim 环境与规范



\### 5.1 安装与版本



\* 使用 \*\*Manim Community Edition v0.19.0\*\*：



&nbsp; ```bash

&nbsp; pip install manim

&nbsp; ```



&nbsp; 文档和安装说明参考官方文档（安装章节）(\[Manim Community | Documentation]\[3])



\* 这是目前社区稳定版本，文档齐全，也有中文文档可参考（manim-docs-zh-hans）。(\[GitHub]\[4])



\### 5.2 与 prompt 保持一致的代码约束



在 `提示词.md` 的基础上，你的 system prompt 里已经统一要求：



\* 纯中文文本：`Text()`

\* 纯数学公式：`MathTex()`

\* 混合内容：拆开后用 `VGroup()` 组合

\* 使用 `MovingCameraScene` 时才用 `self.camera.frame` 做镜头移动

\* 所有公式必须是合法 LaTeX



这些约束 + `GeneratedScene` 统一命名，可以极大降低代码出错率，同时也让自动解析和渲染更简单。



---



\## 六、可以借鉴的论文/系统思路



其实你要做的东西和 2025 年的一篇工作 \*\*“Manimator: Transforming Research Papers into Visual Explanations”\*\* 很像：它也是用 LLM 把自然语言 / 论文 PDF 转成结构化场景描述，然后再转成 Manim 代码。(\[arXiv]\[5])



你现在的方案本质上是一个简化版：



1\. \*\*自然语言 → 场景描述（带公式、时间线、镜头、颜色等）\*\*

2\. \*\*场景描述 → Manim 代码\*\*

3\. \*\*自动渲染 + 自动检查 +（可选）错误反馈再修复\*\*



`提示词.md` 已经把这个“二阶段”流程内嵌到一次调用里，让 `kimi-k2-thinking` 在内部完成这两个步骤，并且自己检查代码，你只需要抽取代码+渲染即可。



---



\## 七、小结：一个可直接实施的最小可用版本（MVP）



1\. \*\*准备环境\*\*



&nbsp;  \* 安装 Python 3.10+、`openai>=1.0`、`manim`（CE v0.19.0）

&nbsp;  \* 在系统环境中配置 `MOONSHOT\_API\_KEY`(\[Moonshot AI]\[1])



2\. \*\*准备 prompt\*\*



&nbsp;  \* 把 `提示词.md` 放在后端项目根目录

&nbsp;  \* 在 system prompt 中追加机器可读约束（代码块、类名等）



3\. \*\*实现后端\*\*



&nbsp;  \* 用 `openai.OpenAI(base\_url="https://api.moonshot.cn/v1")` 调用 `kimi-k2-thinking`

&nbsp;  \* 解析返回内容中的 ```python 代码块

&nbsp;  \* 写入 `generated\_scene.py`，执行 `manim -qk generated\_scene.py GeneratedScene`

&nbsp;  \* 返回视频文件路径



4\. \*\*前端 / CLI\*\*



&nbsp;  \* 可以先做一个命令行脚本：



&nbsp;    ```bash

&nbsp;    python cli\_generate.py "帮我可视化极限 lim\_{n→∞} (1 + 1/n)^n 的几何意义"

&nbsp;    ```

&nbsp;  \* 后续再封装成 Web 界面即可。



